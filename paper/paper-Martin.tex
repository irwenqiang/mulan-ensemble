\section{Introduction}
In many fields, the labeled data may be insufficient in quantity while the unlabeled may be vast. When it comes to the domain of textual data, the reasons for classification of newspaper articles, academic papers or aviation safety reports as in our work are obvious. Manual classification of existing documents or of the extensive amount of newly created documents is unfeasible. It is not only time consuming and expensive, manual annotators may also produce diverse and inadequate classifications. All these limitations have led to the development of automatic multi-label classifiers.

Using ensemble techniques Sanden and Zhang \cite{sanden2011enhancing} were able to obtain better results in multi-label music genre classification than just using a single classifier. In this paper, our aim is to apply and evaluate various ensemble techniques on multi-label text classification.

The data set examined in this paper is a subset of the Aviation Safety Reporting System (ASRS) data set. The collection \emph{tmc2007} contains 28596 NASA aviation safety reports in free text form with 49060 discrete attributes corresponding to terms in the collection. Each document is represented as a term incidence vector. The safety reports are provided with 22 labels, each of them representing a problem type that appears during flights. For our purposes, subset containing 2000 randomly selected instances was used. In order to reduce the computational costs of experiments, we used a set of 500 features. The 500 features were selected in compliance with Tsoumakas and Vlahavas \cite{TsoumakasVlahavas2007kLablesets}. For each label the $\chi^{2}$ feature ranking method was used to obtain a ranking of all features for that label. The top 500 features were selected based on the their maximum rank over all labels \cite{TsoumakasVlahavas2007kLablesets}. Average cardinality in the collection is 2.2.

The rest of the paper is organized as follows. In the next section we provide a summary of related work. After that, we briefly describe multi-label classification algorithms, classifiers and ensemble techniques. In Section 4 we present the Experiment setup. In Section 5 we discuss the results and finally, Section 6 concludes our work.

\section{Related Work}
Ensemble methods combine results of multiple predictive models to achieve better performance than using any of the predictive models separately. Ensemble techniques originated in bagging predictors \cite{breiman1996bagging}, which is a method that trains mutliple versions of a predictor and which relies on their plurality vote when predicting a class. Bagging predictors and other ensemble techniques \cite{sanden2011enhancing} have shown a substantial increase in accuracy. The ensemble methods also tend to produce better results with models showing high diversity among each other. 

Some work on ensemble techniques has been done by Shi, Kong, Yu and Wang \cite{kong2011ensemble}. They give a study of multi-label ensemble learning with focus on building a set of learners. Their proposed solution can efficiently improve the generalization ability of multi-label learning system and hence enhance the predictive performance of the classifier.

The work of Kubat, Sarinnapakorn and Dendamrongvit \cite{kubat2010induction}, deals with induction in multi-label text classification. They propose an induction technique of a set of subclassifiers that are applied on a same training set but use different features, and how to combine their outputs.

Sanden and Zhang \cite{sanden2011enhancing} propose a set of ensemble techniques to obtain better results as with individual multi-label classification algorithms. These techniques also help to overcome the drawbacks of individual classifiers. Their experimental study deals with music genre classification but can be beneficial for other domains as well. 
